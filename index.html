<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ORBIT Surgical">
  <meta name="keywords" content="ORBIT Surgical">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ORBIT-Surgical: An Open-Simulation Framework for Learning Surgical Augmented Dexterity</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-T5R477R2CR"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-T5R477R2CR');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">  
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://orbit-surgical.github.io/sufia/">
            SuFIA
          </a>
          <a class="navbar-item" href="https://isaac-orbit.github.io/">
            ORBIT
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">ORBIT-Surgical: An Open-Simulation Framework for Learning Surgical Augmented Dexterity</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://quincy-u.github.io/">Qinxi Yu</a><sup>*,1</sup>,</span>
            <span class="author-block">
              <a href="https://masoudmoghani.com/">Masoud Moghani</a><sup>*,1</sup>,</span>
            <span class="author-block">
              <a href="https://kdharmarajan.com/">Karthik Dharmarajan</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://ch.linkedin.com/in/vincent-schorp-05b68a181">Vincent Schorp</a><sup>2</sup>,</span>
            <span class="author-block">
              William Chung-Ho Panitch<sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://ca.linkedin.com/in/jasonjzliu">Jingzhou Liu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/kush-hari">Kush Hari</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://qingh097.github.io/">Huang Huang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://mayankm96.github.io/">Mayank Mittal</a><sup>3,5</sup>,</span>
            <span class="author-block">
              <a href="https://goldberg.berkeley.edu/">Ken Goldberg</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://animesh.garg.tech/">Animesh Garg</a><sup>1,4,5</sup></span>
          </div>

          &nbsp;

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Toronto,</span>
            <span class="author-block"><sup>2</sup>University of California, Berkeley,</span>
            <span class="author-block"><sup>3</sup>ETH Zurich,</span><br>
            <span class="author-block"><sup>4</sup>Georgia Institute of Technology,</span>
            <span class="author-block"><sup>5</sup>NVIDIA</span>
          </div>

          &nbsp;

          <div class="is-size-5 publication-authors">
            <span class="author-block">IEEE International Conference on Robotics and Automation (ICRA) 2024</span>
          </div>
 
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2404.16027"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2404.16027"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/NA3xCRHcZsE"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Short Video</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://youtu.be/Jch3N0NqL2k"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Long Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://orbit-surgical.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- 
              <span class="link-block">
                <a href="https://orbit-surgical.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img class="img-responsive img-rounded" src="./static/images/teaser.svg" alt="" width="800" >
<!--       
      <h2 class="subtitle has-text-centered">

      </h2> -->

    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Physics-based simulations have accelerated progress in robot learning for driving, manipulation, and locomotion.
            Yet, a fast, accurate, and robust surgical simulation environment remains a challenge. In this paper,
            we present ORBIT-Surgical, a physics-based surgical robot simulation framework with photorealistic rendering
            in NVIDIA Omniverse. We provide 14 benchmark surgical tasks for the da Vinci Research Kit (dVRK) and
            Smart Tissue Autonomous Robot (STAR) which represent common subtasks in surgical training.
            ORBIT-Surgical leverages GPU parallelization to train reinforcement learning and imitation learning algorithms to facilitate
            study of robot learning to augment human surgical skills. ORBIT-Surgical also facilitates realistic synthetic data generation
            for active perception tasks. We demonstrate ORBIT-Surgical sim-to-real transfer of learned policies onto a physical dVRK robot.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Short Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/NA3xCRHcZsE"></iframe>
        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Long Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/Jch3N0NqL2k"></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
    
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Reinforcement Learning. -->
    <h2 class="title is-3">Reinforcement Learning</h2>
    <div class="content has-text-justified">
      <p>
        ORBIT-Surgical supports various RL frameworks such as RSL-RL and RL-Games to train 
        RL policies for surgical tasks involving rigid and soft objects.
      </p>
    </div>
    <div class="content has-text-centered">
      <video id="needle-handover" autoplay muted loop playsinline width="75%">
        <source src="./static/videos/shunt-insertion.mp4"
                type="video/mp4">
      </video>
      <p class="is-bold">RL Policy for Shunt Insertion</p>
    </div>
    <!--/ Reinforcement Learning. -->

    <!-- Example Tasks. -->
    <h2 class="title is-3">Example Tasks</h2>
    <div class="columns is-centered">

      <!-- Needle Lift. -->
      <div class="column">
        <div class="content">
          <video id="needle-lift" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/needle-lift.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Needle Lift. -->

      <!-- Block Lift. -->
      <div class="column">
        <div class="content">
          <video id="block-lift" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/block-lift.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Block Lift. -->

      <!-- Pick and Place. -->
      <div class="column">
        <div class="content">
          <video id="ring-pickplace" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/ring-pickplace.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Pick and Place. -->

    </div>

    <div class="columns is-centered">

      <!-- Needle Handover. -->
      <div class="column">
        <div class="content">
          <video id="needle-handover" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/needle-handover.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Needle Handover. -->

      <!-- Block Handover. -->
      <div class="column">
        <div class="content">
          <video id="block-handover" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/block-handover.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Block Handover. -->

      <!-- Thread Needle. -->
      <div class="column">
        <div class="content">
          <video id="thread-needle" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/thread-needle.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Thread Needle. -->

    </div>
    <!--/ Example Tasks. -->
    
    <!-- Supplementary Material. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Supplementary Material</h2>

        <div class="content has-text-justified">
          <h2 class="title is-4">S1: Multi-stage Imitation Learning</h2>
          <p>
            Long-horizon tasks are computationally expensive and can be hard to be solved by plain Imitation Learning (IL) algorithms. 
            Instead, multi-stage IL policy can be learned efficiently, where long-horizon tasks are divided into 
            subtasks, and an IL policies are trained to perform each subtask separataely. All subtasks are then chained for 
            end-to-end policy execution. Here, we divide a "Needle Pick and Transfer" task into three stages, i.e. Pick, Handover, and Reach, 
            and trained subpolicies to perform each subtask using behavior cloning. Figure below shows a successful end-to-end policy execution in simulation.
          </p>
          <div class="content has-text-centered">
            <img src="./static/images/IL.svg"
                 class="interpolation-image"
                 alt="Multi-stage imitation learning."/>
            <p class="is-bold"> DualArm - Needle Pick and Transfer task with multi-stage imitation learning. 
              a) starting state of both PSMs, 
              b) right PSM moves down to pick up the needle, 
              c) needle handoff occurs between the PSMs, 
              d) PSMs move away from each other, 
              e) needle is fully transferred to other arm.
            </p>
          </div>

          <h2 class="title is-4">S2: System and Physics Parameters</h2>
          <p>
            We list, categorize and conduct a sensitivity analysis on the simulation parameters in the NVIDIA Isaac Sim. 
            We focus on the representative environment, 'Threaded Needle Pass Ring', where the task is to pass a suture needle with 
            a soft thread through a ring. This environment is selected because it involves extensive interactions between objects, 
            including interactions between deformable objects and rigid objects. To determine the impact of individual parameters, 
            we held all others constant, varied one specific parameter at a time, and noted results.
          </p>
          <h2 class="title is-5">System parameters:</h2>
          <p>
            <ul>
              <li> <b>dt</b> (The physics simulation time-step in seconds). We currently use the value of 0.005 because this is the largest 
            <b>dt</b> value that can provide a fast and stable simulation without jitter. We find that <b>dt</b> of 0.007 cause oscillation 
            when objects interact and deformable object simulation is not stable. We find that the smaller <b>dt</b> value of 0.002 results 
            in a stable yet slower simulation, extending the time required for a single demonstration. For example, the time needed to collect 
            one demonstration is 27 seconds for <b>dt</b> 0.005 and 68 seconds for <b>dt</b> 0.002.</li>
              <li> Solver type [PGS (Projective Gauss-Seidel) or TGS (Truncated Gauss-Seidel)]. Both PGS and TGS offer similar levels of stability and realism in simulations. We used TGS.</li>
          </ul>
          </p>
          <h2 class="title is-5">Physics parameters - Rigid body (suture needle):</h2>
          <p>
            <ul>
              <li> Solver iteration counts: We find this parameter is not a sensitive parameter. Solver iteration counts with value 1 and a 
            much larger value, 128 can provide similar simulation behavior. But a large solver iterations count slows the simulation process. 
            We currently use 1 for both solver_position_iteration_count and solver_velocity_iteration_count, which is the minimum value that ensures stability.</li>
              <li> Contact offset and Rest offset: They are used to control the contact generation. Collision detection starts 
            to generate contact points as soon as two shapes get closer than the sum of their contact offsets. The rest offset quantifies how 
            close a shape gets to others at rest. An “auto compute” feature is provided by Nvidia Isaac Sim. By default, the two offsets, 
            remeshing resolution and triangle count can be all computed automatically by the engine based on the objects’ mesh geometry. 
            These auto computed values can sometimes provide a stable simulation, sometimes will just give bad simulation, depending on the 
            assets’ geometry. We find that the autocomputed contact offset and rest offset already provide a stable and realistic for our suture needle simulation.</li>
              <li> Friction: (both static and dynamic friction). We currently use the value of 0.5 for both static and dynamic friction.</li>
              <li> Damping:  We currently have linear damping of 0.05 and angular damping of 0.05. We find the damping does not have much impact 
            on the stability of the simulation. But larger damping slows down the movement of the rigid body. We use the minimum value that ensures stability.</li>
            </ul>
          </p>
          <h2 class="title is-5">Physics parameters - Soft body (thread):</h2>
          <p>
            <ul>
              <li> Simulation mesh resolution: The simulation mesh resolution is highly sensitive. We currently use the value 28 for the thread. 
              Increasing or decreasing the parameter by a value greater than 3 can lead to a badly simulated collision mesh or mismatch between 
              visual mesh and collision mesh. The simulation mesh resolution needs to be carefully tuned.</li>
              <li> Contact offset and Rest offset: contact offset and rest offset are used to compute the contact with other objects. 
              For the deformable thread, the autocomputed offsets lead to unstable simulation and the offset parameters of the thread are very sensitive. 
              We currently use 0.0003 for contact offset and 0.0002 for rest offset. Increasing or decreasing 0.0001 can lead to mismatch between visual mesh 
              and collision mesh, which can lead to the issue of penetrating other objects during interactions.</li>
              <li> Solver position iteration count: We find this parameter is not a sensitive parameter. Solver position iteration counts with value 1 and a 
              much larger value, 128 can provide similar simulation behavior. But a large solver iterations count slows down the simulation process. We currently 
              use 16 for solver_position_iteration_count, which is the minimum value that ensures stability.</li>
              <li> Remeshing resolution and triangle count: These parameters are used for computing the collision mesh by Nvidia Isaac Sim. We use the auto-computed 
                remeshing resolution and triangle count which gives a stable simulation.</li>
            </ul>
          </p> 

        </div>
      </div>
    </div>
    <!--/ Supplementary Material. -->

    <!-- FAQ. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Frequently Asked Questions</h2>

        <div class="content has-text-justified">
          <p>
            <b>Q:</b> Is ORBIT-Surgical fully free and open-source?
          </p>
          <p>
            <b>A:</b> The underlying robotics simulation application, <a href="https://developer.nvidia.com/isaac-sim">NVIDIA Isaac Sim</a> is free for individual use. ORBIT-Surgical will be released as a free and open-source package upon publication.
          </p>
          <p>
            <b>Q:</b> What are the differences between ORBIT-Surgical and Intuitive Surgical's proprietary SimNow?
          </p>
          <p>
            <b>A:</b> SimNow is a commercial platform for surgeons to practice the skills and techniques needed to perform surgical procedures. 
            It provides a simulated environment that can give the surgeon a realistic experience; ORBIT-Surgical is intended as a benchmark to spur 
            research on supervised autonomy for robot-assisted surgery. We aim to provide simulated environments with a large number of parallel 
            environments for efficient data collection and fast surgical robot learning, as well as accurate physics for sim-to-real transfer of learned policies. 
            In addition, the differences also lie in the way how the simulators can be utilized. Specifically:
            <ul>
              <li> While SimNow is tailored for human practitioners using the MTMs, ORBIT-Surgical offers integration with a range of reinforcement frameworks for learning. </li>
              <li> SimNow is compatible with da Vinci Si, X/Xi, and SP. However, it does not support the da Vinci Research Kit (dVRK) which is commonly found in academic labs. </li>
              <li> SimNow is not open-source while ORBIT-Surgical will be open-sourced upon publication to contribute to the community. </li>
            </ul> 
          </p>
          <p>
            <b>Q:</b> How much time is required to train the RL policies?
          </p>
          <p>
            <b>A:</b> Both tasks involving "Suture Needle Lift" task and "Shunt Insertion" task can be trained under 2 hours on a single NVIDIA RTX 3090 GPU.
          </p>

        </div>
      </div>
    </div>
    <!--/ FAQ. -->

  </div>
</section>



<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="mailto:moghani@cs.toronto.edu">
        <i class="fa fa-envelope"></i>
      </a>
      <a class="icon-link"
         href="https://orbit-surgical.github.io">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://orbit-surgical.github.io" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The template of this website is borrowed from the source code of <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. The template is licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            <!-- Please remember to remove the analytics code included in the header of the website which
            you do not want on your website. -->
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
